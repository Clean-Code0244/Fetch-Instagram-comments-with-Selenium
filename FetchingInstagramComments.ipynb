{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#It doesn't have to be used like this, but if it is used this way, the chromedriver must be in the same folder as your Python file.\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "browser = webdriver.Chrome(service=service)\n",
    "\n",
    "\n",
    "browser.get(\"https://www.instagram.com/\")\n",
    "browser.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "email = browser.find_element(By.XPATH, \"//*[@id='loginForm']/div/div[1]/div/label/input\")\n",
    "password = browser.find_element(By.XPATH, \"//*[@id='loginForm']/div/div[2]/div/label/input\")\n",
    "\n",
    "\n",
    "email.send_keys(\"***\") #You need to put your email here\n",
    "password.send_keys(\"***\") #You need to put your password here\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "login_button = browser.find_element(By.XPATH, \"//*[@id='loginForm']/div/div[3]/button\")\n",
    "login_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "#This has been applied for pop-ups.\n",
    "save_info = browser.find_element(By.XPATH, \"/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/section/main/div/div/div/div/div\")\n",
    "time.sleep(3)\n",
    "save_info.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#This has been applied for pop-ups\n",
    "not_now = browser.find_element(By.CLASS_NAME,\"_a9--._ap36._a9_1\")\n",
    "time.sleep(3)\n",
    "not_now.click()\n",
    "browser.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#This has been applied for search button\n",
    "search_bar = browser.find_element(By.XPATH, \"/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[1]/div/div/div/div/div[2]/div[2]/span/div/a/div\")\n",
    "time.sleep(3)\n",
    "search_bar.click()\n",
    "browser.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "#This has been applied for search text\n",
    "search_text = browser.find_element(By.XPATH, \"/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[1]/div/div/div[2]/div/div/div[2]/div/div/div[1]/div/div/input\")\n",
    "time.sleep(3)\n",
    "search_text.send_keys(\"***\")#Please enter the username of a user whose posts' comments you want to fetch, but you don't follow.For example cbum.\n",
    "time.sleep(5)\n",
    "\n",
    "#This has been done for selecting the first user that appears after the search process.\n",
    "searched_items = browser.find_elements(By.CLASS_NAME, \"x1i10hfl.x1qjc9v5.xjbqb8w.xjqpnuy.xa49m3k.xqeqjp1.x2hbi6w.x13fuv20.xu3j5b3.x1q0q8m5.x26u7qi.x972fbf.xcfux6l.x1qhh985.xm0m39n.x9f619.x1ypdohk.xdl72j9.x2lah0s.xe8uvvx.xdj266r.x11i5rnm.xat24cr.x1mh8g0r.x2lwn1j.xeuugli.xexx8yu.x4uap5.x18d9i69.xkhd6sd.x1n2onr6.x16tdsg8.x1hl2dhg.xggy1nq.x1ja2u2z.x1t137rt.x1q0g3np.x87ps6o.x1lku1pv.x1a2a7pz.x1dm5mii.x16mil14.xiojian.x1yutycm.x1lliihq.x193iq5w.xh8yej3\")\n",
    "time.sleep(3)\n",
    "searched_items[0].click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "for i in range(1,2): # If you have more than 400 follower increase it\n",
    "    scrollable_element = browser.find_element(By.XPATH,\"/html\") \n",
    "    browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollable_element)  # Scroll down inside the element using JavaScript\n",
    "    time.sleep(3)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "all_posts_number = browser.find_element(By.XPATH,\"/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/header/section/ul/li[1]/span/span\").text\n",
    "\n",
    "#The number of posts is represented as a string and contains commas. To avoid errors during casting, a replacement operation is applied in this way.\n",
    "all_posts1 = all_posts_number.replace(\",\",\"\")\n",
    "#By obtaining the number of posts of the user, you can determine how many times the loop will iterate\n",
    "number = int(all_posts1)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(number):\n",
    "    All_Posts = browser.find_elements(By.XPATH, \"/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/div[2]/section/main/div/div[3]/div\")\n",
    "    time.sleep(5)\n",
    "    print(i)\n",
    "    All_Posts[i].click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    three_dot = browser.find_element(By.CSS_SELECTOR, \"body > div.x1n2onr6.xzkaem6 > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe.x1qjc9v5.xjbqb8w.x1lcm9me.x1yr5g0i.xrt01vj.x10y3i5r.xr1yuqi.xkrivgy.x4ii5y1.x1gryazu.x15h9jz8.x47corl.xh8yej3.xir0mxb.x1juhsu6 > div > article > div > div._ae65 > div > div > div._aasi > div > div > div > div\")\n",
    "    time.sleep(3) \n",
    "\n",
    "    three_dot.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    go_to_post_button = browser.find_element(By.CSS_SELECTOR,\"body > div.x1n2onr6.xzkaem6 > div:nth-child(2) > div > div > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div.x7r02ix.xf1ldfh.x131esax.xdajt7p.xxfnqb6.xb88tzc.xw2csxc.x1odjw0f.x5fp0pe > div > div > div > button:nth-child(2)\")\n",
    "    time.sleep(3)\n",
    "    go_to_post_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    PostComment_scroll = browser.find_element(By.CLASS_NAME, \"x5yr21d.xw2csxc.x1odjw0f.x1n2onr6\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #The scroll feature of the page should have gone all the way down. There seems to be an issue here, so I tried to solve this problem as follows.\n",
    "    \n",
    "    for a in range(60):\n",
    "        browser.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", PostComment_scroll)  # Scroll down inside the element using JavaScript\n",
    "        time.sleep(3)\n",
    "        get_all_comments = browser.find_elements(By.CLASS_NAME,\"x5yr21d.xw2csxc.x1odjw0f.x1n2onr6\")\n",
    "    \n",
    "    comment_list = []\n",
    "    \n",
    "    time.sleep(10)\n",
    "    \n",
    "    for user_comments in get_all_comments:\n",
    "        comment_list.append(user_comments.text)\n",
    "        print(user_comments.text)\n",
    "    \n",
    "    time.sleep(10)\n",
    "    #This has been done to save the comments made on each post to separate text files.\n",
    "    with open(f\"post_{i+1}_comments.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"\\n\".join(comment_list))\n",
    "            \n",
    "    time.sleep(3)\n",
    "    browser.back()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
